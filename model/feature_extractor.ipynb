{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8922212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from collections import Counter\n",
    "import whois\n",
    "import tldextract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bce7550",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = tldextract.TLDExtract(cache_dir='.tld_cache', suffix_list_urls=None)\n",
    "ip_pattern = re.compile(r'^\\d{1,3}(\\.\\d{1,3}){3}$')\n",
    "shorteners_set = {\"bit.ly\", \"t.co\", \"tinyurl.com\", \"goo.gl\", \"ow.ly\", \"is.gd\", \"buff.ly\", \"cutt.ly\"}\n",
    "keywords_set = {\"secure\", \"account\", \"update\", \"free\", \"lucky\", \"bonus\", \"click\", \"offer\", \"winner\", \"login\", \"verify\", \"banking\", \"confirm\", \"password\", \"signin\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f308ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_entropy(s: str) -> float:\n",
    "    if not s:\n",
    "        return 0.0\n",
    "    probs = [c / len(s) for c in Counter(s).values()]\n",
    "    return -sum(p * math.log2(p) for p in probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50894ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_date(value):\n",
    "    if value is None:\n",
    "        return None\n",
    "    if isinstance(value, pd.Timestamp):\n",
    "        return value.to_pydatetime()\n",
    "    if isinstance(value, list):\n",
    "        flat = []\n",
    "        for v in value:\n",
    "            if isinstance(v, list):\n",
    "                flat.extend(v)\n",
    "            else:\n",
    "                flat.append(v)\n",
    "        flat = [v for v in flat if v is not None]\n",
    "        if not flat:\n",
    "            return None\n",
    "        return flat[0]\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e37f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_whois_features(features, url):\n",
    "    try:\n",
    "        w = whois.whois(url)\n",
    "        creation = normalize_date(w.creation_date)\n",
    "        expiration = normalize_date(w.expiration_date)\n",
    "\n",
    "        now = pd.Timestamp.now()\n",
    "        features[\"domain_age\"] = (now - pd.Timestamp(creation)).days if creation else -1\n",
    "        features[\"days_to_expire\"] = (pd.Timestamp(expiration) - now).days if expiration else -1\n",
    "        features[\"registration_length\"] = (\n",
    "            (pd.Timestamp(expiration) - pd.Timestamp(creation)).days\n",
    "            if creation and expiration else -1\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è WHOIS chyba pri {url}: {e}\")\n",
    "        features[\"domain_age\"] = -1\n",
    "        features[\"days_to_expire\"] = -1\n",
    "        features[\"registration_length\"] = -1\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da5873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_url_features(url: str, phishing: int = 0) -> dict:\n",
    "    parsed = urlparse(url)\n",
    "    hostname = parsed.hostname or \"\"\n",
    "    path = parsed.path or \"\"\n",
    "    query = parsed.query or \"\"\n",
    "\n",
    "    ext = extractor(url)\n",
    "    url_lower = url.lower()\n",
    "\n",
    "    full_domain = f\"{ext.domain}\"\n",
    "    if ext.suffix and not full_domain.endswith(ext.suffix):\n",
    "        full_domain += f\".{ext.suffix}\"\n",
    "\n",
    "    features = {\n",
    "        \"phishing\": phishing,\n",
    "        \"url\": url,\n",
    "        \"url_len\": len(url),\n",
    "        \"host_len\": len(hostname),\n",
    "        \"path_len\": len(path),\n",
    "        \"query_len\": len(query),\n",
    "        \"is_https\": 1 if parsed.scheme == \"https\" else 0,\n",
    "        \"count_dots\": hostname.count(\".\"),\n",
    "        \"count_hyphen\": url.count(\"-\"),\n",
    "        \"count_at\": url.count(\"@\"),\n",
    "        \"count_qm\": url.count(\"?\"),\n",
    "        \"count_eq\": url.count(\"=\"),\n",
    "        \"count_slash\": url.count(\"/\"),\n",
    "        \"count_double_slash\": url.count(\"//\") - 1 if url.count(\"//\") > 1 else 0,\n",
    "        \"count_digits\": sum(c.isdigit() for c in url),\n",
    "        \"has_ip\": 1 if ip_pattern.match(hostname) else 0,\n",
    "        \"has_shortener\": 1 if full_domain in shorteners_set else 0,\n",
    "        \"has_keyword\": 1 if any(kw in url_lower for kw in keywords_set) else 0,\n",
    "        \"subdomain_len\": len(ext.subdomain),\n",
    "        \"domain\": ext.domain,\n",
    "        \"suffix\": ext.suffix,\n",
    "        \"domain_entropy\": url_entropy(hostname)\n",
    "    }\n",
    "\n",
    "    extract_whois_features(features, full_domain)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5486b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(url: str, phishing: int, retries: int = 9, delay: float = 0.5):\n",
    "    for attempt in range(1, retries + 1):\n",
    "        try:\n",
    "            features = extract_url_features(url, phishing)\n",
    "\n",
    "            # Retry ak WHOIS ne√∫spe≈°n√Ω\n",
    "            if features.get(\"domain_age\", -1) == -1 and attempt < retries:\n",
    "                raise ValueError(\"WHOIS failed, retrying...\")\n",
    "\n",
    "            if attempt > 1:\n",
    "                print(f\"‚úÖ {url} succeeded on attempt {attempt}\")\n",
    "            return features\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è {url} attempt {attempt}/{retries} failed: {e}\")\n",
    "            if attempt < retries:\n",
    "                time.sleep(delay * attempt + random.uniform(0, 0.3))\n",
    "            else:\n",
    "                print(f\"‚ùå {url} failed all {retries} attempts\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960567d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_urls(input_file: str, output_file: str, phishing: int = 0, max_workers: int = 10, limit: int = None):\n",
    "    \"\"\"Spracuje URL zo s√∫boru (txt alebo csv) paralelne s retry logikou.\"\"\"\n",
    "    # Naƒç√≠tanie URL\n",
    "    if input_file.endswith(\".csv\"):\n",
    "        df = pd.read_csv(input_file)\n",
    "        urls = df[\"url\"].astype(str).tolist() if \"url\" in df.columns else df.iloc[:, 0].astype(str).tolist()\n",
    "    else:\n",
    "        with open(input_file, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            urls = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "    if limit:\n",
    "        urls = urls[:limit]\n",
    "\n",
    "    records = []\n",
    "    failed = []\n",
    "\n",
    "    print(f\"üß© Naƒç√≠tan√Ωch {len(urls)} URL, sp√∫≈°≈•am spracovanie s {max_workers} vl√°knami...\")\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(worker, u, phishing): u for u in urls}\n",
    "        total = len(futures)\n",
    "\n",
    "        for i, future in enumerate(as_completed(futures), 1):\n",
    "            u = futures[future]\n",
    "            try:\n",
    "                res = future.result()\n",
    "                if res:\n",
    "                    records.append(res)\n",
    "                else:\n",
    "                    records.append(u)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå V√Ωnimka pri {u}: {e}\")\n",
    "                records.append(u)\n",
    "\n",
    "            if i % 20 == 0 or i == total:\n",
    "                print(f\"Progress {i}/{total} | Success: {len(records)} | Failed: {len(failed)}\")\n",
    "                if records:\n",
    "                    out_df = pd.DataFrame(records)\n",
    "                    out_df.to_csv(output_file, index=False, mode='a', header=not os.path.exists(output_file))\n",
    "                    records.clear()\n",
    "\n",
    "    print(f\"‚úÖ Hotovo. V√Ωsledok: {output_file}\")\n",
    "    return pd.read_csv(output_file) if os.path.exists(output_file) else pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79677e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = process_urls(\n",
    "    input_file=\"../dataset/phishing.txt\",\n",
    "    output_file=\"../dataset/df_phishing.csv\",\n",
    "    phishing=1,\n",
    "    max_workers=90,\n",
    "    limit=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c786b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = process_urls(\n",
    "    input_file=\"../dataset/benign.txt\",\n",
    "    output_file=\"../dataset/df_benign.csv\",\n",
    "    phishing=0,\n",
    "    max_workers=90,\n",
    "    limit=10000\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
